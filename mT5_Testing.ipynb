{"cells":[{"cell_type":"markdown","metadata":{"id":"uc7r28zQxaSN"},"source":["### Model Call"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3570,"status":"ok","timestamp":1661802033480,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"p7P_CKiSOuxS","outputId":"0c106653-da22-4184-b0de-0f33f72f80b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Google Drive Mounting\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"H3hXBTM8weHv","executionInfo":{"status":"ok","timestamp":1661802033481,"user_tz":-360,"elapsed":13,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["# 'base' variable has to store the path to the folder where the model, test set and validation set of BanglaRQA is saved/available/uploaded/stored\n","# so set the 'base' variable path to the folder of the where you have uploaded/saved the model, test set and validation set\n","base = '/content/drive/MyDrive/BQA'       #sample\n","\n","# 'test_file_name' variable has to store file name of the test set of BanglaRQA\n","# so set the 'test_file_name' variable as the file anme of the test set of BanglaRQA\n","test_file_name = 'Test.json' #sample\n","\n","# 'validation_file_name' variable has to store file name of the validation set of BanglaRQA\n","# so set the 'validation_file_name' variable as the file anme of the validation set of BanglaRQA\n","validation_file_name = 'Validation.json'      #sample\n","\n","\n","# 'model_name' variable has to store file name of the saved/uploaded/stroed model that you want to test\n","# so set the 'model_name' variable as the file anme of saved/uploaded/stroed model you want to test\n","#model_name = 'model_weights_epoch_10.pth'         #sample\n","model_name = 'mT5_model_weights_epoch_2.pth'  "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3218,"status":"ok","timestamp":1661802036688,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"q36L4wu8Q8ua","outputId":"1d156985-60d5-43dc-f1ae-2f5b23f3a14a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n"]}],"source":["!pip install transformers[sentencepiece]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4719,"status":"ok","timestamp":1661802041391,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"dbesKgNAweBm","outputId":"89f66cdb-b3dd-4258-d5b7-517c4b8d333c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/csebuetnlp/normalizer\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-v7pm_k56\n","  Running command git clone -q https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-v7pm_k56\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1) (2022.6.2)\n","Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1) (1.4.2)\n","Requirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.7/dist-packages (from normalizer==0.0.1) (6.0.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.5)\n"]}],"source":["pip install git+https://github.com/csebuetnlp/normalizer"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"9mlFQbtl0zJH","executionInfo":{"status":"ok","timestamp":1661802041392,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"6ALEI5KY5Duh","executionInfo":{"status":"ok","timestamp":1661802054097,"user_tz":-360,"elapsed":12709,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["# calling the model BanglaT5 to use it as a class\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\", use_fast=False)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90920,"status":"ok","timestamp":1661802145013,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"OUKtzkcjzHqD","outputId":"e4e73b47-b391-42db-c3fe-275c48f46e96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MT5ForConditionalGeneration(\n","  (shared): Embedding(250112, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(250112, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(250112, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",")"]},"metadata":{},"execution_count":17}],"source":["from transformers import AdamW\n","\n","# setup GPU/CPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# move model over to detected device\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","\n","#calling the checkpoint and loading the parameters of the saved model for evaluation\n","checkpoint = torch.load(base + '/'+ model_name)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","model.to(device)\n","\n","\n","model.eval()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"CiGBwUJpyHTM","executionInfo":{"status":"ok","timestamp":1661802145014,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["from collections import Counter\n","\n","# these functions are heavily influenced by the HF squad_metrics.py script\n","def normalize_text(s):\n","    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n","    import string, re\n","\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    #'''\n","    common_tokens = Counter(pred_tokens) & Counter(truth_tokens)\n","    common_tokens = sum(common_tokens.values())\n","    #'''\n","\n","    '''\n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    common_tokens = len(common_tokens)\n","    '''\n","    \n","    # if there are no common tokens then f1 = 0\n","    if common_tokens == 0:\n","        return 0\n","    \n","    prec = 1.0 * common_tokens / len(pred_tokens)\n","    rec = 1.0 * common_tokens / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)\n"]},{"cell_type":"code","source":["import numpy as np\n","from scipy.optimize import linear_sum_assignment\n","\n","def get_updated_f1(prediction, truth):\n","  # first e prediction k ; diye bhag korte hobe\n","  # truth keo ; diye bhag korte hobe\n","  splitted_prediction = prediction.split(';')\n","  #print(splitted_prediction)\n","  splitted_truth = truth.split(';')\n","  #print(splitted_truth)\n","\n","  # most probably pair wise compute_f1 chalaite hobe\n","  scores = np.zeros([len(splitted_truth), len(splitted_prediction)])\n","  for gold_index, gold_item in enumerate(splitted_truth):\n","    for pred_index, pred_item in enumerate(splitted_prediction):\n","      scores[gold_index, pred_index] = compute_f1(pred_item, gold_item)\n","\n","  #print(scores)\n","\n","  row_ind, col_ind = linear_sum_assignment(-scores)\n","\n","  max_scores = np.zeros([max(len(splitted_truth), len(splitted_prediction))])\n","  for row, column in zip(row_ind, col_ind):\n","    max_scores[row] = max(max_scores[row], scores[row, column])\n","  \n","  #print(max_scores)\n","\n","  # align korte hobe kemne jani na\n","\n","  # protita prediction er average nite hobe\n","  # average ta return korte hobe\n","  f1 = np.mean(max_scores)\n","  return f1\n","\n","#get_updated_f1(\"aaaa qqqq; sdfs fsf; fssfsfs\", \"aaaa; fsr qqqq; ooooo; a\");"],"metadata":{"id":"iEwyGgEH9JhK","executionInfo":{"status":"ok","timestamp":1661802145014,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"xEp3BMNbzArV","executionInfo":{"status":"ok","timestamp":1661802145015,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["import numpy\n","\n","def get_answer(question,context):\n","  source_encoding=tokenizer(\n","    normalize(question),\n","    normalize(context),\n","    max_length=1024,\n","    padding=\"max_length\",\n","    truncation=\"only_second\",\n","    return_attention_mask=True,\n","    add_special_tokens=True,\n","    return_tensors=\"pt\").to(device)\n","  \n","  #print(source_encoding)\n","  \n","  generated_ids=model.generate(\n","      input_ids=source_encoding[\"input_ids\"],\n","      attention_mask=source_encoding[\"attention_mask\"],\n","      num_beams = 1,\n","      max_length=256,\n","      repetition_penalty=2.5,\n","      length_penalty=1.0,\n","      early_stopping= True,\n","      use_cache = True,\n","  )\n","  \n","  #print(generated_ids)\n","\n","  preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids]\n","\n","  return \"\".join(preds), generated_ids"]},{"cell_type":"markdown","metadata":{"id":"QwVCi3Eqp2ga"},"source":["### BanglaRQA Validation"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"goy7KN6hqBmg","executionInfo":{"status":"ok","timestamp":1661802146395,"user_tz":-360,"elapsed":1385,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["# loading the validation dataset for calculating the EM and F1 scores on BanglaRQA's validation set\n","\n","import json\n","import os\n","\n","f = open(os.path.join(base,validation_file_name))\n","  \n","data_val = json.load(f)\n","  \n","data_val.keys()\n","  \n","data_val = data_val['data']"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"mxhmesagrv9f","executionInfo":{"status":"ok","timestamp":1661802149336,"user_tz":-360,"elapsed":2943,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["context_val = []\n","question_val = []\n","answer_val = []\n","answer_type_val = []\n","\n","for i in range(len(data_val)):\n","    for j in range(len(data_val[i]['qas'])):\n","        context_val.append(normalize(data_val[i]['context']))\n","        question_val.append(normalize(data_val[i]['qas'][j]['question_text']))\n","        answer_val.append(normalize(data_val[i]['qas'][j]['answers']['answer_text'][0]))\n","        answer_type_val.append(normalize(data_val[i]['qas'][j]['answers']['answer_type'][0]))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276643,"status":"ok","timestamp":1661802425969,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"rPK5I92DsaUv","outputId":"9e0a756c-2a72-4225-915b-cf42708cf5a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["No of sample in Validation set:  1484\n","Validation set EM score:  0.5539083557951483\n","Validation set F1 score:  0.7139687279677472\n"]}],"source":["sample_total = len(context_val)\n","print('No of sample in Validation set: ', sample_total)\n","\n","f1 = 0.0\n","em = 0.0\n","\n","with torch.no_grad():\n","    l = len(context_val)\n","    for i in range(l):\n","        question = {\n","            \"context\": context_val[i],\n","            \"question\": question_val[i]\n","            }\n","\n","        pred, ids = get_answer(question[\"question\"],question[\"context\"])\n","        if(answer_type_val[i] == 'multiple spans'):\n","          f1 = f1 + get_updated_f1(pred, answer_val[i])\n","        else:\n","          f1 = f1 + compute_f1(pred, answer_val[i])\n","        em = em + compute_exact_match(pred, answer_val[i])\n","\n","print('Validation set EM score: ', em/sample_total)\n","print('Validation set F1 score: ', f1/sample_total)"]},{"cell_type":"markdown","metadata":{"id":"R6XHZK77xfKz"},"source":["### BanglaRQA Test"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"04f5OTH2wyCU","executionInfo":{"status":"ok","timestamp":1661802426755,"user_tz":-360,"elapsed":790,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["# loading the test dataset for calculating the EM and F1 scores on BanglaRQA's test set\n","\n","import json\n","import os\n","\n","f = open(os.path.join(base,test_file_name))\n","  \n","data_test = json.load(f)\n","  \n","data_test.keys()\n","\n","data_test = data_test['data']"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"X1ti0SFoybZJ","executionInfo":{"status":"ok","timestamp":1661802430058,"user_tz":-360,"elapsed":3304,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["context_test = []\n","question_test = []\n","answer_test = []\n","question_type_test = []\n","answer_type_test = []\n","\n","for i in range(len(data_test)):\n","    for j in range(len(data_test[i]['qas'])):\n","        context_test.append(normalize(data_test[i]['context']))\n","        question_test.append(normalize(data_test[i]['qas'][j]['question_text']))\n","        question_type_test.append(normalize(data_test[i]['qas'][j]['question_type']))\n","        answer_test.append(normalize(data_test[i]['qas'][j]['answers']['answer_text'][0]))\n","        answer_type_test.append(normalize(data_test[i]['qas'][j]['answers']['answer_type'][0]))"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"xb8jHexsG3CW","executionInfo":{"status":"ok","timestamp":1661802430059,"user_tz":-360,"elapsed":6,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["anslysis = {\n","    'answerable_f1': 0.0,\n","    'answerable_em': 0.0,\n","    'answerable_cnt': 0.0,\n","\n","    'unanswerable_f1': 0.0,\n","    'unanswerable_em': 0.0,\n","    'unanswerable_cnt': 0.0,\n","\n","    'factoid_f1': 0.0,\n","    'factoid_em': 0.0,\n","    'factoid_cnt': 0.0,\n","\n","    'causal_f1': 0.0,\n","    'causal_em': 0.0,\n","    'causal_cnt': 0.0,\n","\n","    'confirmation_f1': 0.0,\n","    'confirmation_em': 0.0,\n","    'confirmation_cnt': 0.0,\n","\n","    'list_f1': 0.0,\n","    'list_em': 0.0,\n","    'list_cnt': 0.0,\n","}"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278778,"status":"ok","timestamp":1661802708832,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"cQkz8o2fyoZ9","outputId":"3f4f7eda-26d6-4050-dc27-ff27b36abe85"},"outputs":[{"output_type":"stream","name":"stdout","text":["No of samples in Test Set:  1493\n","----------------------------------------------------------------------------------------\n","\n","Test set EM score:  0.5351640991292699\n","Test set F1 score:  0.6882998688233362\n","\n","----------------------------------------------------------------------------------------\n","Accuracy based on answerable/unanserable questions: ------------------------------------\n","\n","Answerabale_em:  0.4297153024911032\n","Answerabale_f1:  0.6331242919512826\n","\n","Unnswerabale_em:  0.8563685636856369\n","Unnswerabale_f1:  0.8563685636856369\n","\n","----------------------------------------------------------------------------------------\n","Accuracy based on different question type:----------------------------------------------\n","\n","Factoid_em:  0.5666023166023166\n","Facoid_f1:  0.7156409588327447\n","\n","causal_em:  0.4140127388535032\n","causal_f1:  0.5773551324676959\n","\n","confirmation_em:  0.8235294117647058\n","confirmation_f1:  0.8235294117647058\n","\n","list_em:  0.21341463414634146\n","list_f1:  0.5096519207627438\n","\n","----------------------------------------------------------------------------------------\n"]}],"source":["sample_total = len(context_test)\n","print('No of samples in Test Set: ',sample_total)\n","\n","f1_total = 0.0\n","em_total = 0.0\n","\n","with torch.no_grad():\n","    l = len(context_test)\n","    for i in range(l):\n","        question = {\n","            \"context\": context_test[i],\n","            \"question\": question_test[i]\n","            }\n","\n","        pred, ids = get_answer(question[\"question\"],question[\"context\"])\n","        if(answer_type_test[i] == 'multiple spans'):\n","          f1 = get_updated_f1(pred, answer_test[i])\n","        else:\n","          f1 = compute_f1(pred, answer_test[i])\n","        f1_total = f1_total + f1\n","        em = compute_exact_match(pred, answer_test[i])\n","        em_total = em_total + em\n","\n","        if(answer_test[i] == ''):\n","          anslysis['unanswerable_cnt'] = anslysis['unanswerable_cnt'] +1\n","          anslysis['unanswerable_f1'] = anslysis['unanswerable_f1'] + f1\n","          anslysis['unanswerable_em'] = anslysis['unanswerable_em'] + em\n","        else:\n","          anslysis['answerable_cnt'] = anslysis['answerable_cnt'] +1\n","          anslysis['answerable_f1'] = anslysis['answerable_f1'] + f1\n","          anslysis['answerable_em'] = anslysis['answerable_em'] + em\n","          \n","        if(question_type_test[i] == 'factoid'):\n","          anslysis['factoid_cnt'] = anslysis['factoid_cnt'] +1\n","          anslysis['factoid_f1'] = anslysis['factoid_f1'] + f1\n","          anslysis['factoid_em'] = anslysis['factoid_em'] + em\n","        elif (question_type_test[i] == 'causal'):\n","          anslysis['causal_cnt'] = anslysis['causal_cnt'] +1\n","          anslysis['causal_f1'] = anslysis['causal_f1'] + f1\n","          anslysis['causal_em'] = anslysis['causal_em'] + em\n","        elif (question_type_test[i] == 'confirmation'):\n","          anslysis['confirmation_cnt'] = anslysis['confirmation_cnt'] +1\n","          anslysis['confirmation_f1'] = anslysis['confirmation_f1'] + f1\n","          anslysis['confirmation_em'] = anslysis['confirmation_em'] + em\n","        elif (question_type_test[i] == 'list'):\n","          anslysis['list_cnt'] = anslysis['list_cnt'] +1\n","          anslysis['list_f1'] = anslysis['list_f1'] + f1\n","          anslysis['list_em'] = anslysis['list_em'] + em\n","\n","\n","print('----------------------------------------------------------------------------------------')\n","print()\n","print('Test set EM score: ', em_total/sample_total)\n","print('Test set F1 score: ', f1_total/sample_total)\n","print()\n","print('----------------------------------------------------------------------------------------')\n","\n","print('Accuracy based on answerable/unanserable questions: ------------------------------------')\n","print()\n","print('Answerabale_em: ', anslysis['answerable_em']/anslysis['answerable_cnt'])\n","print('Answerabale_f1: ', anslysis['answerable_f1']/anslysis['answerable_cnt'])\n","print()\n","print('Unnswerabale_em: ', anslysis['unanswerable_em']/anslysis['unanswerable_cnt'])\n","print('Unnswerabale_f1: ', anslysis['unanswerable_f1']/anslysis['unanswerable_cnt'])\n","print()\n","print(\"----------------------------------------------------------------------------------------\")\n","\n","print('Accuracy based on different question type:----------------------------------------------')\n","print()\n","print('Factoid_em: ', anslysis['factoid_em']/anslysis['factoid_cnt'])\n","print('Facoid_f1: ', anslysis['factoid_f1']/anslysis['factoid_cnt'])\n","print()\n","print('causal_em: ', anslysis['causal_em']/anslysis['causal_cnt'])\n","print('causal_f1: ', anslysis['causal_f1']/anslysis['causal_cnt'])\n","print()\n","print('confirmation_em: ', anslysis['confirmation_em']/anslysis['confirmation_cnt'])\n","print('confirmation_f1: ', anslysis['confirmation_f1']/anslysis['confirmation_cnt'])\n","print()\n","print('list_em: ', anslysis['list_em']/anslysis['list_cnt'])\n","print('list_f1: ', anslysis['list_f1']/anslysis['list_cnt'])\n","print()\n","print('----------------------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"75z_UlVfRp-X","executionInfo":{"status":"ok","timestamp":1661802708833,"user_tz":-360,"elapsed":15,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["answer_anslysis = {\n","    'single_f1': 0.0,\n","    'single_em': 0.0,\n","    'single_cnt': 0.0,\n","\n","    'multi_f1': 0.0,\n","    'multi_em': 0.0,\n","    'multi_cnt': 0.0,\n","\n","    'yes_f1': 0.0,\n","    'yes_em': 0.0,\n","    'yes_cnt': 0.0,\n","}"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254232,"status":"ok","timestamp":1661802963053,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"ADOsecJGRmNu","outputId":"db6d089b-0062-4503-819e-0be6621ff082"},"outputs":[{"output_type":"stream","name":"stdout","text":["No of samples in Test set:  1493\n","Accuracy based on different answer type:-----------------------------------------------\n","\n","single_span_em:  0.4432748538011696\n","single_span_f1:  0.6505867395782698\n","\n","multiple_spans_em:  0.06493506493506493\n","multiple_spans_f1:  0.39857170008975085\n","\n","yes_no_em:  0.8173913043478261\n","yes_no_f1:  0.8173913043478261\n","\n","---------------------------------------------------------------------------------------\n"]}],"source":["sample_total = len(context_test)\n","print('No of samples in Test set: ', sample_total)\n","\n","with torch.no_grad():\n","    l = len(context_test)\n","    for i in range(l):\n","        question = {\n","            \"context\": context_test[i],\n","            \"question\": question_test[i]\n","            }\n","\n","        if(answer_test[i] != ''):  \n","          pred, ids = get_answer(question[\"question\"],question[\"context\"])\n","          if(answer_type_test[i] == 'multiple spans'):\n","            f1 = get_updated_f1(pred, answer_test[i])\n","          else:\n","            f1 = compute_f1(pred, answer_test[i])\n","          em = compute_exact_match(pred, answer_test[i])  \n","          \n","          if(answer_type_test[i] == 'single span'):\n","            answer_anslysis['single_cnt'] = answer_anslysis['single_cnt'] +1\n","            answer_anslysis['single_f1'] = answer_anslysis['single_f1'] + f1\n","            answer_anslysis['single_em'] = answer_anslysis['single_em'] + em\n","          elif (answer_type_test[i] == 'multiple spans'):\n","            answer_anslysis['multi_cnt'] = answer_anslysis['multi_cnt'] +1\n","            answer_anslysis['multi_f1'] = answer_anslysis['multi_f1'] + f1\n","            answer_anslysis['multi_em'] = answer_anslysis['multi_em'] + em\n","          elif (answer_type_test[i] == 'yes/no'):\n","            answer_anslysis['yes_cnt'] = answer_anslysis['yes_cnt'] +1\n","            answer_anslysis['yes_f1'] = answer_anslysis['yes_f1'] + f1\n","            answer_anslysis['yes_em'] = answer_anslysis['yes_em'] + em\n","\n","print('Accuracy based on different answer type:-----------------------------------------------')\n","print()\n","print('single_span_em: ', answer_anslysis['single_em']/answer_anslysis['single_cnt'])\n","print('single_span_f1: ', answer_anslysis['single_f1']/answer_anslysis['single_cnt'])\n","print()\n","print('multiple_spans_em: ', answer_anslysis['multi_em']/answer_anslysis['multi_cnt'])\n","print('multiple_spans_f1: ', answer_anslysis['multi_f1']/answer_anslysis['multi_cnt'])\n","print()\n","print('yes_no_em: ', answer_anslysis['yes_em']/answer_anslysis['yes_cnt'])\n","print('yes_no_f1: ', answer_anslysis['yes_f1']/answer_anslysis['yes_cnt'])\n","print()\n","print('---------------------------------------------------------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"dQ8BWhm4xH7j"},"source":["### bn_squad Test"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":8967,"status":"ok","timestamp":1661802972006,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"Iec-IGnlw-t5","outputId":"4bbf8372-02df-425f-e513-103f14e07a66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     || 365 kB 15.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     || 212 kB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     || 115 kB 63.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     || 127 kB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}],"source":["pip install datasets"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"tWx8Nzl1xCQM","executionInfo":{"status":"ok","timestamp":1661802972670,"user_tz":-360,"elapsed":677,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["from datasets import load_dataset"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["e892d1e843e746baa9edd907200d8fae","c804a0a97d0f4e558966c18913f3417b","b78cac3b2dc1434e84efcbb94864dc1a","28038fa522cd4e83a5a9fa7c1e6e884d","0bbc48dda81344779d3d8f21fd3e0765","8f4f61ed131d407a9b5421eec1f4e5e4","7dbd6ec2a2654d42a2e8ef8be18260e9","593d1ecd2c274379b1868417390d3e61","cf380ae820d443f18da93b425332082b","8c3ac1ad625147de8ea2729034381bc8","59a1d6ac21f641919b462852b32ee255","6f556360716546d3bcc803925039c68f","8e7295b8d408428d861095bc415106f8","492e3fa8917c43b0857fc1e0886891b5","04bac83493794eb6baa88f309eb1ec9c","59bcee232a3d4527a995a51e0e2dc155","51e278b58dac4abf8590435451d6a8ac","1592f844bdf24c7da1ea8d66aa89882a","ba53abe8e811428d89d91f390bcad7c1","5ff37e43638d4280aa6aebc8cfefedb9","60f4f3c81705455f976be2476e684d1b","cae63e9ecd76417ba879e63cce8aa567","80d2019cfe79490f8915b72aa28e4757","47dbeb8b8fca49c3a41927d7845e00a2","e1ba1080bb984609b5210b66eaab528c","06c2e737e3c24baca0de2aca6a016442","1bab0cd8d8db4334a91a3c2b38f412e1","3ddbffc684014690aeb080dda06f1974","2bd3c1ff5eb5475992a401065a598733","dd41cb6f0da5452095f841bfb3e9d649","b20a35ccbe684c7881d94de045008613","d0d6cc68455d4305b561a14b647e9aee","4c111b2dc6ef44c4ac0be28dbeba86ef","095393e07f2e48cdb2d82075b8560749","0eda51b879444a2894aab955cad2f8f8","7e4fd2def77c4d09b6feab0fd38e30af","bad2adb8cdcf40c5839d901dc2f1e8dc","3edfde9aeff048f3a88ee71e5cfa9ba5","1da37b29622f467eabb248d75492583d","4783297a17a24382a0fa0132c1b4d47a","b61181d189304c3484fb7c71c3a7f0a2","b74d9ebc3f844b72a280e7f8a7b5beee","e7e7e0d9115c41d984b4695233551bbe","591e1188495549fe9905a10dc4b74b53","23c065e4c8f64642ba03d48d52c29ba9","3d75a1d2a648422789dae2b72812f288","fc166e88908c423abdc4363a1723b99a","136839e568434f09bc2a5505efd906c3","98646e0c8faf438c81b08c8d4a601ff5","7b9f0f8cd34f4931b18dee1db60274e2","4372778f7df84a1b9e656b53e3f0f5f2","64877379a28c417a8e9afadb9667f220","e36f3aedaece49b8aaad6c3d298dcd9c","dbf74dc592bd417c8d537a7806b2d52e","b9f07f835d574aa1a6afdf96af1aad1a"]},"executionInfo":{"elapsed":29378,"status":"ok","timestamp":1661803002045,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"},"user_tz":-360},"id":"q-WV7Og1xE98","outputId":"ab735d44-c021-4c86-c54f-0e4c9dfc91f6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e892d1e843e746baa9edd907200d8fae"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset squad_bn/squad_bn to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/8.43M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f556360716546d3bcc803925039c68f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d2019cfe79490f8915b72aa28e4757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095393e07f2e48cdb2d82075b8560749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c065e4c8f64642ba03d48d52c29ba9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset squad_bn downloaded and prepared to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b. Subsequent calls will reuse this data.\n"]}],"source":["test_dataset_squad = load_dataset(\"csebuetnlp/squad_bn\", split=\"test\")"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Di8vrx4exFlA","executionInfo":{"status":"ok","timestamp":1661803005239,"user_tz":-360,"elapsed":3208,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":["test_context_squad = []\n","test_question_squad = []\n","test_answer_squad = []\n","\n","for i in range(len(test_dataset_squad)):\n","    if(len(test_dataset_squad[i]['answers']['text']) != 0):\n","        test_context_squad.append(normalize(test_dataset_squad[i]['context']))\n","        test_question_squad.append(normalize(test_dataset_squad[i]['question']))\n","        test_answer_squad.append(normalize(test_dataset_squad[i]['answers']['text'][0]))\n","    else:\n","        test_context_squad.append(normalize(test_dataset_squad[i]['context']))\n","        test_question_squad.append(normalize(test_dataset_squad[i]['question']))\n","        test_answer_squad.append(normalize(''))"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndb16IVlxQAV","executionInfo":{"status":"ok","timestamp":1661803206402,"user_tz":-360,"elapsed":201165,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}},"outputId":"07ca8634-58de-4049-e017-9c6b8fc2da6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2504\n","Accuracy of our model on bn_quad dataset: ---------------------------------------------\n","\n","EM score:  0.6050319488817891\n","F1 score:  0.6353065829881258\n","\n","---------------------------------------------------------------------------------------\n"]}],"source":["f1_total = 0.0\n","em_total = 0.0\n","\n","sample_total = len(test_context_squad)\n","print(sample_total)\n","\n","with torch.no_grad():\n","    l = len(test_context_squad)\n","    for i in range(l):\n","        question = {\n","            \"context\": test_context_squad[i],\n","            \"question\": test_question_squad[i]\n","            }\n","\n","        pred, ids = get_answer(question[\"question\"],question[\"context\"])\n","        '''print(i)\n","        print(test_question_squad[i])\n","        print(pred)\n","        print(test_answer_squad[i])\n","        print()'''\n","        f1_total = f1_total + compute_f1(pred, test_answer_squad[i])\n","        em_total = em_total + compute_exact_match(pred, test_answer_squad[i])\n","\n","\n","print('Accuracy of our model on bn_quad dataset: ---------------------------------------------')\n","print()\n","print('EM score: ', em_total/sample_total)\n","print('F1 score: ', f1_total/sample_total)\n","print()\n","print('---------------------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"W-mkjJkn5pLp","executionInfo":{"status":"ok","timestamp":1661803206402,"user_tz":-360,"elapsed":21,"user":{"displayName":"Mukta's Cuisine","userId":"09477569564665203851"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["uc7r28zQxaSN","QwVCi3Eqp2ga","dQ8BWhm4xH7j"],"name":"mT5_Testing.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e892d1e843e746baa9edd907200d8fae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c804a0a97d0f4e558966c18913f3417b","IPY_MODEL_b78cac3b2dc1434e84efcbb94864dc1a","IPY_MODEL_28038fa522cd4e83a5a9fa7c1e6e884d"],"layout":"IPY_MODEL_0bbc48dda81344779d3d8f21fd3e0765"}},"c804a0a97d0f4e558966c18913f3417b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4f61ed131d407a9b5421eec1f4e5e4","placeholder":"","style":"IPY_MODEL_7dbd6ec2a2654d42a2e8ef8be18260e9","value":"Downloading builder script: 100%"}},"b78cac3b2dc1434e84efcbb94864dc1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_593d1ecd2c274379b1868417390d3e61","max":4202,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf380ae820d443f18da93b425332082b","value":4202}},"28038fa522cd4e83a5a9fa7c1e6e884d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c3ac1ad625147de8ea2729034381bc8","placeholder":"","style":"IPY_MODEL_59a1d6ac21f641919b462852b32ee255","value":" 4.20k/4.20k [00:00&lt;00:00, 103kB/s]"}},"0bbc48dda81344779d3d8f21fd3e0765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f4f61ed131d407a9b5421eec1f4e5e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dbd6ec2a2654d42a2e8ef8be18260e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"593d1ecd2c274379b1868417390d3e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf380ae820d443f18da93b425332082b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c3ac1ad625147de8ea2729034381bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59a1d6ac21f641919b462852b32ee255":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f556360716546d3bcc803925039c68f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e7295b8d408428d861095bc415106f8","IPY_MODEL_492e3fa8917c43b0857fc1e0886891b5","IPY_MODEL_04bac83493794eb6baa88f309eb1ec9c"],"layout":"IPY_MODEL_59bcee232a3d4527a995a51e0e2dc155"}},"8e7295b8d408428d861095bc415106f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51e278b58dac4abf8590435451d6a8ac","placeholder":"","style":"IPY_MODEL_1592f844bdf24c7da1ea8d66aa89882a","value":"Downloading data: 100%"}},"492e3fa8917c43b0857fc1e0886891b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba53abe8e811428d89d91f390bcad7c1","max":8432345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ff37e43638d4280aa6aebc8cfefedb9","value":8432345}},"04bac83493794eb6baa88f309eb1ec9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60f4f3c81705455f976be2476e684d1b","placeholder":"","style":"IPY_MODEL_cae63e9ecd76417ba879e63cce8aa567","value":" 8.43M/8.43M [00:00&lt;00:00, 44.3MB/s]"}},"59bcee232a3d4527a995a51e0e2dc155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e278b58dac4abf8590435451d6a8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1592f844bdf24c7da1ea8d66aa89882a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba53abe8e811428d89d91f390bcad7c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff37e43638d4280aa6aebc8cfefedb9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60f4f3c81705455f976be2476e684d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae63e9ecd76417ba879e63cce8aa567":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80d2019cfe79490f8915b72aa28e4757":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47dbeb8b8fca49c3a41927d7845e00a2","IPY_MODEL_e1ba1080bb984609b5210b66eaab528c","IPY_MODEL_06c2e737e3c24baca0de2aca6a016442"],"layout":"IPY_MODEL_1bab0cd8d8db4334a91a3c2b38f412e1"}},"47dbeb8b8fca49c3a41927d7845e00a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ddbffc684014690aeb080dda06f1974","placeholder":"","style":"IPY_MODEL_2bd3c1ff5eb5475992a401065a598733","value":"Generating train split: "}},"e1ba1080bb984609b5210b66eaab528c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd41cb6f0da5452095f841bfb3e9d649","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b20a35ccbe684c7881d94de045008613","value":1}},"06c2e737e3c24baca0de2aca6a016442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0d6cc68455d4305b561a14b647e9aee","placeholder":"","style":"IPY_MODEL_4c111b2dc6ef44c4ac0be28dbeba86ef","value":" 117264/0 [00:21&lt;00:00, 11603.06 examples/s]"}},"1bab0cd8d8db4334a91a3c2b38f412e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ddbffc684014690aeb080dda06f1974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bd3c1ff5eb5475992a401065a598733":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd41cb6f0da5452095f841bfb3e9d649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b20a35ccbe684c7881d94de045008613":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0d6cc68455d4305b561a14b647e9aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c111b2dc6ef44c4ac0be28dbeba86ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095393e07f2e48cdb2d82075b8560749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0eda51b879444a2894aab955cad2f8f8","IPY_MODEL_7e4fd2def77c4d09b6feab0fd38e30af","IPY_MODEL_bad2adb8cdcf40c5839d901dc2f1e8dc"],"layout":"IPY_MODEL_3edfde9aeff048f3a88ee71e5cfa9ba5"}},"0eda51b879444a2894aab955cad2f8f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da37b29622f467eabb248d75492583d","placeholder":"","style":"IPY_MODEL_4783297a17a24382a0fa0132c1b4d47a","value":"Generating test split: "}},"7e4fd2def77c4d09b6feab0fd38e30af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61181d189304c3484fb7c71c3a7f0a2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b74d9ebc3f844b72a280e7f8a7b5beee","value":1}},"bad2adb8cdcf40c5839d901dc2f1e8dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7e7e0d9115c41d984b4695233551bbe","placeholder":"","style":"IPY_MODEL_591e1188495549fe9905a10dc4b74b53","value":" 2385/0 [00:00&lt;00:00, 9005.56 examples/s]"}},"3edfde9aeff048f3a88ee71e5cfa9ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da37b29622f467eabb248d75492583d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4783297a17a24382a0fa0132c1b4d47a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61181d189304c3484fb7c71c3a7f0a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b74d9ebc3f844b72a280e7f8a7b5beee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7e7e0d9115c41d984b4695233551bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"591e1188495549fe9905a10dc4b74b53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23c065e4c8f64642ba03d48d52c29ba9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d75a1d2a648422789dae2b72812f288","IPY_MODEL_fc166e88908c423abdc4363a1723b99a","IPY_MODEL_136839e568434f09bc2a5505efd906c3"],"layout":"IPY_MODEL_98646e0c8faf438c81b08c8d4a601ff5"}},"3d75a1d2a648422789dae2b72812f288":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b9f0f8cd34f4931b18dee1db60274e2","placeholder":"","style":"IPY_MODEL_4372778f7df84a1b9e656b53e3f0f5f2","value":"Generating validation split: "}},"fc166e88908c423abdc4363a1723b99a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_64877379a28c417a8e9afadb9667f220","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e36f3aedaece49b8aaad6c3d298dcd9c","value":1}},"136839e568434f09bc2a5505efd906c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbf74dc592bd417c8d537a7806b2d52e","placeholder":"","style":"IPY_MODEL_b9f07f835d574aa1a6afdf96af1aad1a","value":" 2450/0 [00:00&lt;00:00, 9530.64 examples/s]"}},"98646e0c8faf438c81b08c8d4a601ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b9f0f8cd34f4931b18dee1db60274e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4372778f7df84a1b9e656b53e3f0f5f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64877379a28c417a8e9afadb9667f220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e36f3aedaece49b8aaad6c3d298dcd9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbf74dc592bd417c8d537a7806b2d52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9f07f835d574aa1a6afdf96af1aad1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}